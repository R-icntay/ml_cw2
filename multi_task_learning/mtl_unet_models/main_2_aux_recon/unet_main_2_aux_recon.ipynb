{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTL 3D Unet with 2 decoders: main_task ->2, aux_task ->reconstruction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import monai\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from shutil import copyfile\n",
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(2022)\n",
    "\n",
    "# Read all files ending with _img.nii\n",
    "img_path = Path(\"data/data\")\n",
    "img_files = list(img_path.glob(\"*_img.nii\")) # Image and mask are in the same folder\n",
    "num_images = len(img_files) \n",
    "\n",
    "# Create train, validation and test splits\n",
    "train_split = int(0.8 * num_images)\n",
    "val_split = int(0.10 * num_images)\n",
    "test_split = int(num_images - (train_split + val_split))\n",
    "\n",
    "# Shuffle the image files\n",
    "random.shuffle(img_files)\n",
    "\n",
    "# Split the dataset\n",
    "train_images = img_files[:train_split]\n",
    "val_images = img_files[train_split:(train_split + val_split)]\n",
    "test_images = img_files[(train_split + val_split): ]\n",
    "\n",
    "# Create train, validation and test directories\n",
    "train_image_dir = Path(img_path / \"train_images\")\n",
    "train_mask_dir = Path(img_path / \"train_masks\")\n",
    "val_image_dir = Path(img_path / \"val_images\")\n",
    "val_mask_dir = Path(img_path / \"val_masks\")\n",
    "test_image_dir = Path(img_path / \"test_images\")\n",
    "test_mask_dir = Path(img_path / \"test_masks\")\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "if not os.path.exists(train_image_dir) and not os.path.exists(train_mask_dir) and not os.path.exists(val_image_dir) and not os.path.exists(val_mask_dir) and not os.path.exists(test_image_dir) and not os.path.exists(test_mask_dir):\n",
    "    for directory in [train_image_dir, train_mask_dir, val_image_dir, val_mask_dir, test_image_dir, test_mask_dir]:\n",
    "        directory.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "    # Copy the images and their corresponding segmentation masks to their respective directories\n",
    "    for directory, images in zip([train_image_dir, val_image_dir, test_image_dir], [train_images, val_images, test_images]):\n",
    "        for image in images:\n",
    "            # Copy image\n",
    "            copyfile(image, directory / image.name)\n",
    "\n",
    "            # Get corresponding segmentation mask\n",
    "            mask = image.name.replace(\"_img.nii\", \"_mask.nii\")\n",
    "\n",
    "            # Copy segmentation mask\n",
    "            copyfile(image.parent / mask, image.parent / directory.name.replace(\"images\", \"masks\") / mask)\n",
    "\n",
    "\n",
    "# # Sanity check\n",
    "# train_images_s = list(train_image_dir.glob(\"*\"))\n",
    "# train_images_s = [image.name.removesuffix(\"_img.nii\") for image in train_images_s]\n",
    "# train_masks_s = list(train_mask_dir.glob(\"*\"))\n",
    "# train_masks_s = [mask.name.removesuffix(\"_mask.nii\") for mask in train_masks_s]\n",
    "# train_images_s == train_masks_s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create building blocks of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Define a Residual block\n",
    "class residual_block(nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements a residual block which consists of two convolution layers with group normalization\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, n_groups = 8):\n",
    "        super().__init__()\n",
    "        # First convolution layer\n",
    "        self.first_conv = nn.Conv3d(in_channels = in_channels, out_channels = out_channels, kernel_size = 3, padding = 1, bias=False)\n",
    "        self.first_norm = nn.GroupNorm(num_groups = n_groups, num_channels = out_channels)\n",
    "        self.act1 = nn.SiLU() # Swish activation function\n",
    "\n",
    "        # Second convolution layer\n",
    "        self.second_conv = nn.Conv3d(in_channels = out_channels, out_channels = out_channels, kernel_size = 3, padding = 1, bias = False)\n",
    "        self.second_norm = nn.GroupNorm(num_groups = n_groups, num_channels = out_channels)\n",
    "        self.act2 = nn.SiLU() # Swish activation function\n",
    "\n",
    "        # Add dropout to the residual block\n",
    "        self.dropout = nn.Dropout3d(p = 0.2)\n",
    "\n",
    "        # If the number of input channels is not equal to the number of output channels,\n",
    "        # then use a 1X1 convolution layer to compensate for the difference in dimensions\n",
    "        # This allows the input to have the same dimensions as the output of the residual block\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv3d(in_channels = in_channels, out_channels = out_channels, kernel_size = 1, padding = 0, bias = False)\n",
    "        else:\n",
    "            # Pass the input as is\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "    # Pass the input through the residual block\n",
    "    def forward(self, x):\n",
    "        # Store the input\n",
    "        input = x\n",
    "\n",
    "        # Pass input through the first convolution layer\n",
    "        x = self.act1(self.first_norm(self.first_conv(x)))\n",
    "\n",
    "        # Pass the output of the first convolution layer through the second convolution layer\n",
    "        x = self.act2(self.second_norm(self.second_conv(x)))\n",
    "\n",
    "        # Add dropout\n",
    "        x = self.dropout(x)\n",
    "\n",
    "\n",
    "        # Add the input to the output of the second convolution layer\n",
    "        # This is the skip connection\n",
    "        x = x + self.shortcut(input)\n",
    "        return x\n",
    "\n",
    "# Implement the DownSample block that occurs after each residual block\n",
    "class down_sample(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.max_pool = nn.MaxPool3d(kernel_size = 2, stride = 2)\n",
    "\n",
    "    # Pass the input through the downsample block\n",
    "    def forward(self, x):\n",
    "        x = self.max_pool(x)\n",
    "        return x\n",
    "\n",
    "# Implement the UpSample block that occurs in the decoder path/expanding path\n",
    "class up_sample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolution transpose layer to upsample the input\n",
    "        self.up_sample = nn.ConvTranspose3d(in_channels = in_channels, out_channels = out_channels, kernel_size = 2, stride = 2, bias = False)\n",
    "\n",
    "    # Pass the input through the upsample block\n",
    "    def forward(self, x):\n",
    "        x = self.up_sample(x)\n",
    "        return x\n",
    "\n",
    "# Implement the crop and concatenate layer\n",
    "class crop_and_concatenate(nn.Module):\n",
    "    def forward(self, upsampled, bypass):\n",
    "        # Crop the upsampled feature map to match the dimensions of the bypass feature map\n",
    "        if upsampled.shape[2:] != bypass.shape[2:]:\n",
    "            upsampled = nn.Upsample(size = bypass.shape[2:], mode=\"trilinear\", align_corners=True)(upsampled)\n",
    "\n",
    "        #upsampled = torchvision.transforms.functional.resize(upsampled, size = bypass.shape[2:], antialias=True)\n",
    "        x = torch.cat([upsampled, bypass], dim = 1) # Concatenate along the channel dimension\n",
    "        return x\n",
    "\n",
    "# Implement an attention block\n",
    "class attention_block(nn.Module):\n",
    "    def __init__(self, skip_channels, gate_channels, inter_channels = None, n_groups = 8):\n",
    "        super().__init__()\n",
    "\n",
    "        if inter_channels is None:\n",
    "            inter_channels = skip_channels // 2\n",
    "\n",
    "        # Implement W_g i.e the convolution layer that operates on the gate signal\n",
    "        # Upsample gate signal to be the same size as the skip connection\n",
    "        self.W_g = up_sample(in_channels = gate_channels, out_channels = skip_channels)\n",
    "        self.W_g_norm = nn.GroupNorm(num_groups = n_groups, num_channels = skip_channels)\n",
    "        self.W_g_act = nn.SiLU() # Swish activation function\n",
    "\n",
    "        # Implement W_x i.e the convolution layer that operates on the skip connection\n",
    "        self.W_x = nn.Conv3d(in_channels = skip_channels, out_channels = inter_channels, kernel_size = 1, padding = 0, bias = False)\n",
    "        self.W_x_norm = nn.GroupNorm(num_groups = n_groups, num_channels = inter_channels)\n",
    "        self.W_x_act = nn.SiLU() # Swish activation function\n",
    "\n",
    "        # Implement phi i.e the convolution layer that operates on the output of W_x + W_g\n",
    "        self.phi = nn.Conv3d(in_channels = inter_channels, out_channels = 1, kernel_size = 1, padding = 0, bias = False)\n",
    "        #self.phi_norm = nn.GroupNorm(num_groups = n_groups, num_channels = 1)\n",
    "        #self.phi_act = nn.SiLU() # Swish activation function\n",
    "\n",
    "        # Implement the sigmoid activation function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # Implement the Swish activation function\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "        # Implement final group normalization layer\n",
    "        self.final_norm = nn.GroupNorm(num_groups = n_groups, num_channels = skip_channels)\n",
    "\n",
    "    # Pass the input through the attention block\n",
    "    def forward(self, skip_connection, gate_signal):\n",
    "        # Upsample the gate signal to match the channels of the skip connection\n",
    "        gate_signal = self.W_g(gate_signal)\n",
    "        # Ensure that the sizes of the skip connection and the gate signal match before addition\n",
    "        if gate_signal.shape[2:] != skip_connection.shape[2:]:\n",
    "            gate_signal = nn.Upsample(size = skip_connection.shape[2:], mode=\"trilinear\", align_corners=True)(gate_signal)\n",
    "            #gate_signal = torchvision.transforms.functional.resize(gate_signal, size = skip_connection.shape[2:], antialias=True)\n",
    "        # Project to the intermediate channels\n",
    "        gate_signal = self.W_x(gate_signal)\n",
    "\n",
    "        # Project the skip connection to the intermediate channels\n",
    "        skip_signal = self.W_x(skip_connection)\n",
    "\n",
    "        # Add the skip connection and the gate signal\n",
    "        add_xg = gate_signal + skip_signal\n",
    "\n",
    "        # Pass the output of the addition through the activation function\n",
    "        add_xg = self.act(add_xg)\n",
    "\n",
    "        # Pass the output of attention through a 1x1 convolution layer to obtain the attention map\n",
    "        attention_map = self.sigmoid(self.phi(add_xg))\n",
    "\n",
    "        # Multiply the skip connection with the attention map\n",
    "        # Perform element-wise multiplication\n",
    "        skip_connection = torch.mul(skip_connection, attention_map)\n",
    "\n",
    "        skip_connection = nn.Conv3d(in_channels = skip_connection.shape[1], out_channels = skip_connection.shape[1], kernel_size = 1, bias=False).to(device)(skip_connection)\n",
    "        skip_connection = self.act(self.final_norm(skip_connection))\n",
    "\n",
    "        return skip_connection\n",
    "\n",
    "## Implement a 3D residual attention U-Net - Single head model that segments all 8 ROIs\n",
    "class ResidualAttention3DUnet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_groups = 4, n_channels = [16, 32, 64, 128, 256]):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the contracting path: residual blocks followed by downsampling\n",
    "        self.down_conv = nn.ModuleList(residual_block(in_chans, out_chans) for in_chans, out_chans in\n",
    "                                       [(in_channels, n_channels[0]), (n_channels[0], n_channels[1]), (n_channels[1], n_channels[2]), (n_channels[2], n_channels[3])])\n",
    "        self.down_samples = nn.ModuleList(down_sample() for _ in range(4))\n",
    "\n",
    "        # Define the bottleneck residual block\n",
    "        self.bottleneck = residual_block(n_channels[3], n_channels[4])\n",
    "\n",
    "\n",
    "        # Define the attention blocks\n",
    "        self.attention_blocks = nn.ModuleList(attention_block(skip_channels = residuals_chans, gate_channels = gate_chans) for gate_chans, residuals_chans in\n",
    "                                              [(n_channels[4], n_channels[3]), (n_channels[3], n_channels[2]), (n_channels[2], n_channels[1]), (n_channels[1], n_channels[0])])\n",
    "\n",
    "\n",
    "        # Define the expanding path: upsample blocks, followed by crop and concatenate, followed by residual blocks\n",
    "        self.upsamples = nn.ModuleList(up_sample(in_chans, out_chans) for in_chans, out_chans in\n",
    "                                       [(n_channels[4], n_channels[3]), (n_channels[3], n_channels[2]), (n_channels[2], n_channels[1]), (n_channels[1], n_channels[0])])\n",
    "        \n",
    "        self.concat = nn.ModuleList(crop_and_concatenate() for _ in range(4))\n",
    "\n",
    "        self.up_conv = nn.ModuleList(residual_block(in_chans, out_chans) for in_chans, out_chans in\n",
    "                                     [(n_channels[4], n_channels[3]), (n_channels[3], n_channels[2]), (n_channels[2], n_channels[1]), (n_channels[1], n_channels[0])])\n",
    "        \n",
    "        # Final 1X1 convolution layer to produce the output segmentation map:\n",
    "        # The primary purpose of 1x1 convolutions is to transform the channel dimension of the feature map,\n",
    "        # while leaving the spatial dimensions unchanged.\n",
    "        self.final_conv = nn.Conv3d(in_channels = n_channels[0] , out_channels = out_channels, kernel_size = 1, padding = 0, bias = False)\n",
    "\n",
    "    # Pass the input through the residual attention U-Net\n",
    "    def forward(self, x):\n",
    "        # Store the skip connections\n",
    "        skip_connections = []\n",
    "       \n",
    "\n",
    "        # Pass the input through the contracting path\n",
    "        for down_conv, down_sample in zip(self.down_conv, self.down_samples):\n",
    "            x = down_conv(x)\n",
    "            skip_connections.append(x)\n",
    "            x = down_sample(x)\n",
    "        \n",
    "        # Pass the output of the contracting path through the bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "\n",
    "        # Initialize the attention block counter and the skip connection counter\n",
    "        att_block_count = 0\n",
    "        skip_connections_count = len(skip_connections)\n",
    "    \n",
    "        # Pass the output of the attention blocks through the expanding path\n",
    "        for up_sample, concat, up_conv in zip(self.upsamples, self.concat, self.up_conv):\n",
    "            gated_attn = self.attention_blocks[att_block_count](skip_connections[skip_connections_count - 1], x)\n",
    "            att_block_count += 1\n",
    "            skip_connections_count -= 1\n",
    "            x = up_sample(x)\n",
    "            x = concat(x, gated_attn)\n",
    "            x = up_conv(x)\n",
    "\n",
    "        # Pass the output of the expanding path through the final convolution layer\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implement a MTL 3D resiidual attention U-Net in a more robust manner\n",
    "class MTLResidualAttention3DUnet(nn.Module):\n",
    "    def __init__(self, in_channels, main_out_channels, aux_out_channels, n_channels = [32, 64, 128, 256, 512], gated_attention = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Choose whether to use gated attention or not\n",
    "        self.gated_attention = gated_attention\n",
    "\n",
    "        # Define the contracting path: residual blocks followed by downsampling\n",
    "        self.down_conv = nn.ModuleList()\n",
    "        in_chans = in_channels\n",
    "        for out_chans in n_channels[:-1]: # Skip the last element since it is the bottleneck\n",
    "            self.down_conv.append(residual_block(in_chans, out_chans))\n",
    "            in_chans = out_chans\n",
    "        \n",
    "        self.down_samples = nn.ModuleList(down_sample() for _ in range(len(n_channels) - 1))\n",
    "\n",
    "        # Define the bottleneck residual block\n",
    "        self.bottleneck = residual_block(in_channels = n_channels[-2], out_channels = n_channels[-1])\n",
    "\n",
    "        ## ------ Decoder block for segmenting main prostate zones: central, transition, background ------ ##\n",
    "        # Define the attention blocks\n",
    "        self.attention_blocks_main = nn.ModuleList()\n",
    "        for gate_chans, residual_chans in zip(n_channels[::-1][:-1], n_channels[::-1][1:]):\n",
    "            self.attention_blocks_main.append(attention_block(skip_channels = residual_chans, gate_channels = gate_chans))\n",
    "        \n",
    "        # Define the expanding path: upsample blocks, followed by crop and concatenate, followed by residual blocks\n",
    "        self.upsamples_main = nn.ModuleList()\n",
    "        for in_chans, out_chans in zip(n_channels[::-1][:-1], n_channels[::-1][1:]):\n",
    "            self.upsamples_main.append(up_sample(in_chans, out_chans))\n",
    "        \n",
    "        self.concat_main = nn.ModuleList(crop_and_concatenate() for _ in range(len(n_channels) - 1))\n",
    "\n",
    "        self.up_conv_main = nn.ModuleList()\n",
    "        for in_chans, out_chans in zip(n_channels[::-1][:-1], n_channels[::-1][1:]):\n",
    "            self.up_conv_main.append(residual_block(in_chans, out_chans))\n",
    "\n",
    "        # Final 1X1 convolution layer to produce the output segmentation map:\n",
    "        # The primary purpose of 1x1 convolutions is to transform the channel dimension of the feature map,\n",
    "        # while leaving the spatial dimensions unchanged.\n",
    "        self.final_conv_main = nn.Conv3d(in_channels = n_channels[0], out_channels = main_out_channels, kernel_size = 1, padding = 0, bias = False) # \n",
    "\n",
    "\n",
    "        ## ------ Decoder block for segmenting the auxilliary zones: Bladder, Rectum, Seminal vesicle, Neurovascular bundle ------ ##\n",
    "        # Define the attention blocks\n",
    "        self.attention_blocks_aux = nn.ModuleList()\n",
    "        for gate_chans, residual_chans in zip(n_channels[::-1][:-1], n_channels[::-1][1:]):\n",
    "            self.attention_blocks_aux.append(attention_block(skip_channels = residual_chans, gate_channels = gate_chans))\n",
    "\n",
    "        # Define the expanding path: upsample blocks, followed by crop and concatenate, followed by residual blocks\n",
    "        self.upsamples_aux = nn.ModuleList()\n",
    "        for in_chans, out_chans in zip(n_channels[::-1][:-1], n_channels[::-1][1:]):\n",
    "            self.upsamples_aux.append(up_sample(in_chans, out_chans))\n",
    "        \n",
    "        self.concat_aux = nn.ModuleList(crop_and_concatenate() for _ in range(len(n_channels) - 1))\n",
    "\n",
    "        self.up_conv_aux = nn.ModuleList()\n",
    "        for in_chans, out_chans in zip(n_channels[::-1][:-1], n_channels[::-1][1:]):\n",
    "            self.up_conv_aux.append(residual_block(in_chans, out_chans))\n",
    "\n",
    "        # Final 1X1 convolution layer to produce the output segmentation map:\n",
    "        # The primary purpose of 1x1 convolutions is to transform the channel dimension of the feature map,\n",
    "        # while leaving the spatial dimensions unchanged.\n",
    "        self.final_conv_aux = nn.Conv3d(in_channels = n_channels[0], out_channels = aux_out_channels, kernel_size = 1, padding = 0, bias = False)\n",
    "\n",
    "\n",
    "    # Pass the input through the residual attention U-Net\n",
    "    # The input is a 5D tensor of shape (batch_size, channels, depth, height, width)\n",
    "    def forward(self, x):\n",
    "        # Store the skip connections\n",
    "        skip_connections = []\n",
    "\n",
    "        # Pass the input through the contracting path\n",
    "        for down_conv, down_sample in zip(self.down_conv, self.down_samples):\n",
    "            x = down_conv(x)\n",
    "            skip_connections.append(x)\n",
    "            x = down_sample(x)\n",
    "\n",
    "        # Pass the output of the contracting path through the bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Define the main and auxilliary variables\n",
    "        x_main = x\n",
    "        x_aux = x\n",
    "\n",
    "        # --- Pass the output of the encoder through the decoder of the main prostate zones --- #\n",
    "        # Initialize the attention block counter and the skip connection counter\n",
    "        attn_block_count = 0\n",
    "        skip_connections_count = len(skip_connections)\n",
    "\n",
    "        # Pass the output of the attention blocks through the expanding path\n",
    "        if self.gated_attention:\n",
    "            for up_sample, concat, up_conv in zip(self.upsamples_main, self.concat_main, self.up_conv_main):\n",
    "                gated_attn = self.attention_blocks_main[attn_block_count](skip_connections[skip_connections_count - 1], x_main)\n",
    "                attn_block_count += 1\n",
    "                skip_connections_count -= 1\n",
    "                x_main = up_sample(x_main)\n",
    "                x_main = concat(x_main, gated_attn)\n",
    "                x_main = up_conv(x_main)\n",
    "        else:\n",
    "            for up_sample, concat, up_conv in zip(self.upsamples_main, self.concat_main, self.up_conv_main):\n",
    "                x_main = up_sample(x_main)\n",
    "                x_main = concat(x_main, skip_connections[skip_connections_count - 1])\n",
    "                x_main = up_conv(x_main)\n",
    "                skip_connections_count -= 1\n",
    "        \n",
    "        # Pass the output of the main decoder through the final convolution layer\n",
    "        x_main = self.final_conv_main(x_main)  # Output segmentation map for the main prostate zones\n",
    "\n",
    "        # --- Pass the output of the encoder through the decoder of the auxilliary prostate zones --- #\n",
    "        # Initialize the attention block counter and the skip connection counter\n",
    "        attn_block_count = 0\n",
    "        skip_connections_count = len(skip_connections)\n",
    "\n",
    "        # Pass the output of the attention blocks through the expanding path\n",
    "        if self.gated_attention:\n",
    "            for up_sample, concat, up_conv in zip(self.upsamples_aux, self.concat_aux, self.up_conv_aux):\n",
    "                gated_attn = self.attention_blocks_aux[attn_block_count](skip_connections[skip_connections_count - 1], x_aux)\n",
    "                attn_block_count += 1\n",
    "                skip_connections_count -= 1\n",
    "                x_aux = up_sample(x_aux)\n",
    "                x_aux = concat(x_aux, gated_attn)\n",
    "                x_aux = up_conv(x_aux)\n",
    "        else:\n",
    "            for up_sample, concat, up_conv in zip(self.upsamples_aux, self.concat_aux, self.up_conv_aux):\n",
    "                x_aux = up_sample(x_aux)\n",
    "                x_aux = concat(x_aux, skip_connections[skip_connections_count - 1])\n",
    "                x_aux = up_conv(x_aux)\n",
    "                skip_connections_count -= 1\n",
    "            \n",
    "        # Pass the output of the auxilliary decoder through the final convolution layer\n",
    "        x_aux = self.final_conv_aux(x_aux) # Output segmentation map for the auxilliary prostate zones\n",
    "\n",
    "        # Return the output segmentation maps for the main and auxilliary prostate zones\n",
    "        return x_main, x_aux\n",
    "\n",
    "# Test whether the model is working\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# modelt = MTLResidualAttention3DUnet(in_channels = 1, main_out_channels = 3, aux_out_channels = 1, n_channels = [32, 64, 128, 256, 512], gated_attention = False).to(device)\n",
    "# x = torch.randn(2, 1, 40, 128, 128).to(device)\n",
    "# x_main, x_aux = modelt(x)\n",
    "# x_main.shape, x_aux.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install monai\n",
    "from monai.utils import first, set_determinism \n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirstd, # Adjust or add the channel dimension of input data to ensure channel_first shape.\n",
    "    #AddChanneld,\n",
    "    CenterSpatialCropd,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    NormalizeIntensityd,\n",
    "    ScaleIntensityd,\n",
    "    Spacingd,\n",
    "    SpatialPadd,\n",
    "    ToTensord,\n",
    "    RandAffined, Resized, RandSpatialCropd,\n",
    "    CropForegroundd, # Crop the foreground region of the input image based on the provided mask to help training and evaluation if the valid part is small in the whole medical image\n",
    "    RandCropByPosNegLabeld, # Crop random patches from image and label based on positive / negative label ratio.\n",
    "    RandGaussianNoised, # Randomly add Gaussian noise to image.\n",
    "    RandGaussianSmoothd, # Randomly smooth image with Gaussian filter.\n",
    "    AdjustContrastd, # Adjust image contrast by gamma value.\n",
    "\n",
    ")\n",
    "\n",
    "# Set deterministic training for reproducibility\n",
    "set_determinism(seed = 2056)\n",
    "\n",
    "# Put the train images and masks in a dictionary\n",
    "train_images = sorted(train_image_dir.glob(\"*\"))\n",
    "train_masks = sorted(train_mask_dir.glob(\"*\"))\n",
    "train_files = [{\"image\": image_name, \"mask\": mask_name} for image_name, mask_name in zip(train_images, train_masks)]\n",
    "\n",
    "# Put the validation images and masks in a dictionary\n",
    "val_images = sorted(val_image_dir.glob(\"*\"))\n",
    "val_masks = sorted(val_mask_dir.glob(\"*\"))\n",
    "val_files = [{\"image\": image_name, \"mask\": mask_name} for image_name, mask_name in zip(val_images, val_masks)]\n",
    "\n",
    "# Put the test images and masks in a dictionary\n",
    "test_images = sorted(test_image_dir.glob(\"*\"))\n",
    "test_masks = sorted(test_mask_dir.glob(\"*\"))\n",
    "test_files = [{\"image\": image_name, \"mask\": mask_name} for image_name, mask_name in zip(test_images, test_masks)]\n",
    "\n",
    "# Create transforms for training\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys = [\"image\", \"mask\"]),\n",
    "        EnsureChannelFirstd(keys = [\"image\", \"mask\"]),\n",
    "        ScaleIntensityd(keys = \"image\"),\n",
    "        CropForegroundd(keys = [\"image\", \"mask\"], source_key = \"image\"),\n",
    "        Spacingd(\n",
    "            keys = [\"image\", \"mask\"],\n",
    "            pixdim = [0.75, 0.75, 2.5],\n",
    "            mode = (\"bilinear\", \"nearest\"), # Interpolation mode for image and mask\n",
    "        ),\n",
    "        # RandCropByPosNegLabeld(\n",
    "        #     keys = [\"image\", \"mask\"],\n",
    "        #     label_key = \"mask\",\n",
    "        #     spatial_size = (256, 256, 40), # Output size of the image [height, width, depth]\n",
    "        #     pos = 1, # Ratio of positive labels in the output image\n",
    "        #     neg = 1, # Ratio of negative labels in the output image\n",
    "        #     num_samples = 4, # Number of random crops\n",
    "        #     image_key = \"image\", # Key of the image to be cropped\n",
    "        #     image_threshold = 0# Threshold to determine the foreground of the image\n",
    "        # ),\n",
    "        RandAffined(\n",
    "            keys = [\"image\", \"mask\"],\n",
    "            mode = (\"bilinear\", \"nearest\"),\n",
    "            prob = 1.0,\n",
    "            spatial_size = (256, 256, 40), # Output size of the image [height, width, depth]\n",
    "            rotate_range = (np.pi / 36, np.pi / 36, np.pi / 36), # Rotation range\n",
    "            scale_range = (0.1, 0.1, 0.1), # will do [-0.1, 0.1] scaling then add 1 so a scaling in the range [0.9, 1.1]\n",
    "            padding_mode=\"zeros\", # This means that the image will be padded with zeros, some images are smaller than 256x256x40\n",
    "        ),\n",
    "        RandGaussianNoised(\n",
    "            keys = \"image\",\n",
    "            prob = 0.15,\n",
    "            mean = 0.0,\n",
    "            std = 0.1\n",
    "\n",
    "        ),\n",
    "        RandGaussianSmoothd(\n",
    "            keys = \"image\",\n",
    "            prob = 0.1,\n",
    "            sigma_x=(0.5, 1.5),\n",
    "            sigma_y=(0.5, 1.5),\n",
    "            sigma_z=(0.5, 1.5)\n",
    "        ),\n",
    "        AdjustContrastd(\n",
    "            keys = \"image\",\n",
    "            gamma = 1.3\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create transforms for validation\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys = [\"image\", \"mask\"]),\n",
    "        EnsureChannelFirstd(keys = [\"image\", \"mask\"]),\n",
    "        ScaleIntensityd(keys = \"image\"),\n",
    "        CropForegroundd(keys = [\"image\", \"mask\"], source_key = \"image\"),\n",
    "        Spacingd(\n",
    "            keys = [\"image\", \"mask\"],\n",
    "            pixdim = [0.75, 0.75, 2.5],\n",
    "            mode = (\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        # since we are not doing data augmentation during validation,\n",
    "        #we simply center crop the image and mask to the specified size of [256, 256, 40]\n",
    "        CenterSpatialCropd(keys = [\"image\", \"mask\"], roi_size = (256, 256, 40)), \n",
    "        SpatialPadd(keys = [\"image\", \"mask\"], spatial_size= (256, 256, 40)) # Some images are smaller than 256x256x40, so we pad them to this size\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Background': 0,\n",
       " 'Bladder': 1,\n",
       " 'Bone': 2,\n",
       " 'Obturator internus': 3,\n",
       " 'Transition zone': 4,\n",
       " 'Central gland': 5,\n",
       " 'Rectum': 6,\n",
       " 'Seminal vesicle': 7,\n",
       " 'Neurovascular bundle': 8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organs = [\"Background\", \"Bladder\", \"Bone\", \"Obturator internus\", \"Transition zone\", \"Central gland\",\n",
    "          \"Rectum\", \"Seminal vesicle\", \"Neurovascular bundle\"]\n",
    "# Create an index dictionary\n",
    "organs_dict = {organ: idx for idx, organ in enumerate(organs)}\n",
    "organs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "# #from tqdm import tqdm\n",
    "# BATCH_SIZE = 2\n",
    "# #train_ds = CacheDataset(data = train_files, transform = train_transforms, cache_rate = 1.0, num_workers = 4)\n",
    "# train_ds = Dataset(data = val_files, transform = train_transforms)\n",
    "# train_dl = DataLoader(dataset = train_ds, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
    "\n",
    "# #val_ds = CacheDataset(data = val_files, transform = val_transforms, cache_rate = 1.0, num_workers = 4)\n",
    "# val_ds = Dataset(data = train_files, transform = val_transforms)\n",
    "# val_dl = DataLoader(dataset = val_ds, batch_size = BATCH_SIZE, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "#from tqdm import tqdm\n",
    "BATCH_SIZE = 2\n",
    "#train_ds = CacheDataset(data = train_files, transform = train_transforms, cache_rate = 1.0, num_workers = 4)\n",
    "train_ds = Dataset(data = train_files, transform = train_transforms)\n",
    "train_dl = DataLoader(dataset = train_ds, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
    "\n",
    "#val_ds = CacheDataset(data = val_files, transform = val_transforms, cache_rate = 1.0, num_workers = 4)\n",
    "val_ds = Dataset(data = val_files, transform = val_transforms)\n",
    "val_dl = DataLoader(dataset = val_ds, batch_size = BATCH_SIZE, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236, 29)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl), len(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Load a trained model\n",
    "# # # Instantiate model\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = MTLResidualAttention3DUnet(in_channels = 1, main_out_channels = 3, aux_out_channels = 4).to(device) #Main: 2 structures + background, Aux: 3 structures + background\n",
    "\n",
    "# # # Load the state dictionary of the model\n",
    "# model.load_state_dict(torch.load(\"models/GA_MTL_pytorch_male_pelvic_segmentation_model_6f.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "\n",
    "lr = 5e-4\n",
    "max_epochs = 100\n",
    "main_out_channels = 3 # Number of structures 2 + background\n",
    "aux_out_channels = 1 # Same channels as input\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Input image has eight anatomical structures of planning interest\n",
    "#model = MTLResidualAttention3DUnet(in_channels = 1, main_out_channels = main_out_channels , aux_out_channels = aux_out_channels, n_channels = [32, 64, 128, 256, 512], gated_attention = True).to(device)#Main: 2 structures + background, Aux: 3 structures + background\n",
    "loss_function = DiceLoss(to_onehot_y = True, softmax = True, include_background=False) # For segmentation Expects BNHW[D] input i.e. batch, channel, height, width, depth, performs softmax on the channel dimension to get a probability distribution\n",
    "reconstruction_loss = torch.nn.L1Loss() # L1 loss for reconstruction\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr) # Decreased the loss after getting a somewhat good model\n",
    "dice_metric_main = DiceMetric(include_background=False, reduction=\"mean\")# Collect the loss and metric values for every iteration\n",
    "#dice_metric_aux = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = max_epochs, eta_min = 1e-6) #** Adopt a cosine annealing learning rate schedule which reduces the learning rate as the training progresses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Epoch 1 / 100\n",
      "\n",
      "Epoch 1 average dice loss for main task: 0.2490\n",
      "\n",
      "Epoch 1 average dice loss for aux task: 0.0113\n",
      "\n",
      "Epoch 1 average total loss for both tasks: 0.3859\n",
      "--------------------\n",
      "Epoch 2 / 100\n",
      "\n",
      "Epoch 2 average dice loss for main task: 0.2225\n",
      "\n",
      "Epoch 2 average dice loss for aux task: 0.0134\n",
      "\n",
      "Epoch 2 average total loss for both tasks: 0.3485\n",
      "--------------------\n",
      "Epoch 3 / 100\n",
      "\n",
      "Epoch 3 average dice loss for main task: 0.2169\n",
      "\n",
      "Epoch 3 average dice loss for aux task: 0.0135\n",
      "\n",
      "Epoch 3 average total loss for both tasks: 0.3402\n",
      "--------------------\n",
      "Epoch 4 / 100\n",
      "\n",
      "Epoch 4 average dice loss for main task: 0.2125\n",
      "\n",
      "Epoch 4 average dice loss for aux task: 0.0105\n",
      "\n",
      "Epoch 4 average total loss for both tasks: 0.3302\n",
      "--------------------\n",
      "Epoch 5 / 100\n",
      "\n",
      "Epoch 5 average dice loss for main task: 0.2044\n",
      "\n",
      "Epoch 5 average dice loss for aux task: 0.0128\n",
      "\n",
      "Epoch 5 average total loss for both tasks: 0.3207\n",
      "--------------------\n",
      "Epoch 6 / 100\n",
      "\n",
      "Epoch 6 average dice loss for main task: 0.2022\n",
      "\n",
      "Epoch 6 average dice loss for aux task: 0.0140\n",
      "\n",
      "Epoch 6 average total loss for both tasks: 0.3187\n",
      "--------------------\n",
      "Epoch 7 / 100\n",
      "\n",
      "Epoch 7 average dice loss for main task: 0.2031\n",
      "\n",
      "Epoch 7 average dice loss for aux task: 0.0113\n",
      "\n",
      "Epoch 7 average total loss for both tasks: 0.3171\n",
      "--------------------\n",
      "Epoch 8 / 100\n",
      "\n",
      "Epoch 8 average dice loss for main task: 0.2049\n",
      "\n",
      "Epoch 8 average dice loss for aux task: 0.0127\n",
      "\n",
      "Epoch 8 average total loss for both tasks: 0.3214\n",
      "--------------------\n",
      "Epoch 9 / 100\n",
      "\n",
      "Epoch 9 average dice loss for main task: 0.2059\n",
      "\n",
      "Epoch 9 average dice loss for aux task: 0.0166\n",
      "\n",
      "Epoch 9 average total loss for both tasks: 0.3272\n",
      "--------------------\n",
      "Epoch 10 / 100\n",
      "\n",
      "Epoch 10 average dice loss for main task: 0.1971\n",
      "\n",
      "Epoch 10 average dice loss for aux task: 0.0114\n",
      "\n",
      "Epoch 10 average total loss for both tasks: 0.3081\n",
      "saved new best metric model\n",
      "\n",
      "Current epoch: 10 current mean dice for main task: 0.8315\n",
      "Best mean dice for main task: 0.8315 at epoch: 10\n",
      "Current epoch: 10 current mean ssim for aux task: 0.9532\n",
      "--------------------\n",
      "Epoch 11 / 100\n",
      "\n",
      "Epoch 11 average dice loss for main task: 0.1959\n",
      "\n",
      "Epoch 11 average dice loss for aux task: 0.0114\n",
      "\n",
      "Epoch 11 average total loss for both tasks: 0.3063\n",
      "--------------------\n",
      "Epoch 12 / 100\n",
      "\n",
      "Epoch 12 average dice loss for main task: 0.1905\n",
      "\n",
      "Epoch 12 average dice loss for aux task: 0.0100\n",
      "\n",
      "Epoch 12 average total loss for both tasks: 0.2967\n",
      "--------------------\n",
      "Epoch 13 / 100\n",
      "\n",
      "Epoch 13 average dice loss for main task: 0.1998\n",
      "\n",
      "Epoch 13 average dice loss for aux task: 0.0085\n",
      "\n",
      "Epoch 13 average total loss for both tasks: 0.3091\n",
      "--------------------\n",
      "Epoch 14 / 100\n",
      "\n",
      "Epoch 14 average dice loss for main task: 0.1937\n",
      "\n",
      "Epoch 14 average dice loss for aux task: 0.0118\n",
      "\n",
      "Epoch 14 average total loss for both tasks: 0.3035\n",
      "--------------------\n",
      "Epoch 15 / 100\n",
      "\n",
      "Epoch 15 average dice loss for main task: 0.1924\n",
      "\n",
      "Epoch 15 average dice loss for aux task: 0.0128\n",
      "\n",
      "Epoch 15 average total loss for both tasks: 0.3027\n",
      "--------------------\n",
      "Epoch 16 / 100\n",
      "\n",
      "Epoch 16 average dice loss for main task: 0.1859\n",
      "\n",
      "Epoch 16 average dice loss for aux task: 0.0124\n",
      "\n",
      "Epoch 16 average total loss for both tasks: 0.2924\n",
      "--------------------\n",
      "Epoch 17 / 100\n",
      "\n",
      "Epoch 17 average dice loss for main task: 0.1859\n",
      "\n",
      "Epoch 17 average dice loss for aux task: 0.0118\n",
      "\n",
      "Epoch 17 average total loss for both tasks: 0.2919\n",
      "--------------------\n",
      "Epoch 18 / 100\n",
      "\n",
      "Epoch 18 average dice loss for main task: 0.1926\n",
      "\n",
      "Epoch 18 average dice loss for aux task: 0.0117\n",
      "\n",
      "Epoch 18 average total loss for both tasks: 0.3018\n",
      "--------------------\n",
      "Epoch 19 / 100\n",
      "\n",
      "Epoch 19 average dice loss for main task: 0.1899\n",
      "\n",
      "Epoch 19 average dice loss for aux task: 0.0124\n",
      "\n",
      "Epoch 19 average total loss for both tasks: 0.2984\n",
      "--------------------\n",
      "Epoch 20 / 100\n",
      "\n",
      "Epoch 20 average dice loss for main task: 0.1879\n",
      "\n",
      "Epoch 20 average dice loss for aux task: 0.0112\n",
      "\n",
      "Epoch 20 average total loss for both tasks: 0.2942\n",
      "\n",
      "Current epoch: 20 current mean dice for main task: 0.8232\n",
      "Best mean dice for main task: 0.8315 at epoch: 10\n",
      "Current epoch: 20 current mean ssim for aux task: 0.9431\n",
      "--------------------\n",
      "Epoch 21 / 100\n",
      "\n",
      "Epoch 21 average dice loss for main task: 0.1845\n",
      "\n",
      "Epoch 21 average dice loss for aux task: 0.0116\n",
      "\n",
      "Epoch 21 average total loss for both tasks: 0.2896\n",
      "--------------------\n",
      "Epoch 22 / 100\n",
      "\n",
      "Epoch 22 average dice loss for main task: 0.1824\n",
      "\n",
      "Epoch 22 average dice loss for aux task: 0.0131\n",
      "\n",
      "Epoch 22 average total loss for both tasks: 0.2879\n",
      "--------------------\n",
      "Epoch 23 / 100\n",
      "\n",
      "Epoch 23 average dice loss for main task: 0.1865\n",
      "\n",
      "Epoch 23 average dice loss for aux task: 0.0111\n",
      "\n",
      "Epoch 23 average total loss for both tasks: 0.2919\n",
      "--------------------\n",
      "Epoch 24 / 100\n",
      "\n",
      "Epoch 24 average dice loss for main task: 0.1812\n",
      "\n",
      "Epoch 24 average dice loss for aux task: 0.0093\n",
      "\n",
      "Epoch 24 average total loss for both tasks: 0.2819\n",
      "--------------------\n",
      "Epoch 25 / 100\n",
      "\n",
      "Epoch 25 average dice loss for main task: 0.1847\n",
      "\n",
      "Epoch 25 average dice loss for aux task: 0.0091\n",
      "\n",
      "Epoch 25 average total loss for both tasks: 0.2869\n",
      "--------------------\n",
      "Epoch 26 / 100\n",
      "\n",
      "Epoch 26 average dice loss for main task: 0.1822\n",
      "\n",
      "Epoch 26 average dice loss for aux task: 0.0106\n",
      "\n",
      "Epoch 26 average total loss for both tasks: 0.2850\n",
      "--------------------\n",
      "Epoch 27 / 100\n",
      "\n",
      "Epoch 27 average dice loss for main task: 0.1841\n",
      "\n",
      "Epoch 27 average dice loss for aux task: 0.0133\n",
      "\n",
      "Epoch 27 average total loss for both tasks: 0.2907\n",
      "--------------------\n",
      "Epoch 28 / 100\n",
      "\n",
      "Epoch 28 average dice loss for main task: 0.1799\n",
      "\n",
      "Epoch 28 average dice loss for aux task: 0.0113\n",
      "\n",
      "Epoch 28 average total loss for both tasks: 0.2824\n",
      "--------------------\n",
      "Epoch 29 / 100\n",
      "\n",
      "Epoch 29 average dice loss for main task: 0.1792\n",
      "\n",
      "Epoch 29 average dice loss for aux task: 0.0119\n",
      "\n",
      "Epoch 29 average total loss for both tasks: 0.2819\n",
      "--------------------\n",
      "Epoch 30 / 100\n",
      "\n",
      "Epoch 30 average dice loss for main task: 0.1774\n",
      "\n",
      "Epoch 30 average dice loss for aux task: 0.0112\n",
      "\n",
      "Epoch 30 average total loss for both tasks: 0.2785\n",
      "\n",
      "Current epoch: 30 current mean dice for main task: 0.8244\n",
      "Best mean dice for main task: 0.8315 at epoch: 10\n",
      "Current epoch: 30 current mean ssim for aux task: 0.9533\n",
      "--------------------\n",
      "Epoch 31 / 100\n",
      "\n",
      "Epoch 31 average dice loss for main task: 0.1771\n",
      "\n",
      "Epoch 31 average dice loss for aux task: 0.0089\n",
      "\n",
      "Epoch 31 average total loss for both tasks: 0.2754\n",
      "--------------------\n",
      "Epoch 32 / 100\n",
      "\n",
      "Epoch 32 average dice loss for main task: 0.1731\n",
      "\n",
      "Epoch 32 average dice loss for aux task: 0.0115\n",
      "\n",
      "Epoch 32 average total loss for both tasks: 0.2724\n",
      "--------------------\n",
      "Epoch 33 / 100\n",
      "\n",
      "Epoch 33 average dice loss for main task: 0.1717\n",
      "\n",
      "Epoch 33 average dice loss for aux task: 0.0123\n",
      "\n",
      "Epoch 33 average total loss for both tasks: 0.2711\n",
      "--------------------\n",
      "Epoch 34 / 100\n",
      "\n",
      "Epoch 34 average dice loss for main task: 0.1731\n",
      "\n",
      "Epoch 34 average dice loss for aux task: 0.0108\n",
      "\n",
      "Epoch 34 average total loss for both tasks: 0.2716\n",
      "--------------------\n",
      "Epoch 35 / 100\n",
      "\n",
      "Epoch 35 average dice loss for main task: 0.1720\n",
      "\n",
      "Epoch 35 average dice loss for aux task: 0.0099\n",
      "\n",
      "Epoch 35 average total loss for both tasks: 0.2689\n",
      "--------------------\n",
      "Epoch 36 / 100\n",
      "\n",
      "Epoch 36 average dice loss for main task: 0.1732\n",
      "\n",
      "Epoch 36 average dice loss for aux task: 0.0089\n",
      "\n",
      "Epoch 36 average total loss for both tasks: 0.2696\n",
      "--------------------\n",
      "Epoch 37 / 100\n",
      "\n",
      "Epoch 37 average dice loss for main task: 0.1690\n",
      "\n",
      "Epoch 37 average dice loss for aux task: 0.0098\n",
      "\n",
      "Epoch 37 average total loss for both tasks: 0.2642\n",
      "--------------------\n",
      "Epoch 38 / 100\n",
      "\n",
      "Epoch 38 average dice loss for main task: 0.1720\n",
      "\n",
      "Epoch 38 average dice loss for aux task: 0.0111\n",
      "\n",
      "Epoch 38 average total loss for both tasks: 0.2703\n",
      "--------------------\n",
      "Epoch 39 / 100\n",
      "\n",
      "Epoch 39 average dice loss for main task: 0.1706\n",
      "\n",
      "Epoch 39 average dice loss for aux task: 0.0102\n",
      "\n",
      "Epoch 39 average total loss for both tasks: 0.2671\n",
      "--------------------\n",
      "Epoch 40 / 100\n",
      "\n",
      "Epoch 40 average dice loss for main task: 0.1679\n",
      "\n",
      "Epoch 40 average dice loss for aux task: 0.0116\n",
      "\n",
      "Epoch 40 average total loss for both tasks: 0.2645\n",
      "\n",
      "Current epoch: 40 current mean dice for main task: 0.8230\n",
      "Best mean dice for main task: 0.8315 at epoch: 10\n",
      "Current epoch: 40 current mean ssim for aux task: 0.9554\n",
      "--------------------\n",
      "Epoch 41 / 100\n",
      "\n",
      "Epoch 41 average dice loss for main task: 0.1712\n",
      "\n",
      "Epoch 41 average dice loss for aux task: 0.0109\n",
      "\n",
      "Epoch 41 average total loss for both tasks: 0.2687\n",
      "--------------------\n",
      "Epoch 42 / 100\n",
      "\n",
      "Epoch 42 average dice loss for main task: 0.1679\n",
      "\n",
      "Epoch 42 average dice loss for aux task: 0.0103\n",
      "\n",
      "Epoch 42 average total loss for both tasks: 0.2633\n",
      "--------------------\n",
      "Epoch 43 / 100\n",
      "\n",
      "Epoch 43 average dice loss for main task: 0.1704\n",
      "\n",
      "Epoch 43 average dice loss for aux task: 0.0108\n",
      "\n",
      "Epoch 43 average total loss for both tasks: 0.2675\n",
      "--------------------\n",
      "Epoch 44 / 100\n",
      "\n",
      "Epoch 44 average dice loss for main task: 0.1687\n",
      "\n",
      "Epoch 44 average dice loss for aux task: 0.0118\n",
      "\n",
      "Epoch 44 average total loss for both tasks: 0.2660\n",
      "--------------------\n",
      "Epoch 45 / 100\n",
      "\n",
      "Epoch 45 average dice loss for main task: 0.1727\n",
      "\n",
      "Epoch 45 average dice loss for aux task: 0.0116\n",
      "\n",
      "Epoch 45 average total loss for both tasks: 0.2718\n",
      "--------------------\n",
      "Epoch 46 / 100\n",
      "\n",
      "Epoch 46 average dice loss for main task: 0.1670\n",
      "\n",
      "Epoch 46 average dice loss for aux task: 0.0089\n",
      "\n",
      "Epoch 46 average total loss for both tasks: 0.2602\n",
      "--------------------\n",
      "Epoch 47 / 100\n",
      "\n",
      "Epoch 47 average dice loss for main task: 0.1673\n",
      "\n",
      "Epoch 47 average dice loss for aux task: 0.0128\n",
      "\n",
      "Epoch 47 average total loss for both tasks: 0.2650\n",
      "--------------------\n",
      "Epoch 48 / 100\n",
      "\n",
      "Epoch 48 average dice loss for main task: 0.1676\n",
      "\n",
      "Epoch 48 average dice loss for aux task: 0.0113\n",
      "\n",
      "Epoch 48 average total loss for both tasks: 0.2638\n",
      "--------------------\n",
      "Epoch 49 / 100\n",
      "\n",
      "Epoch 49 average dice loss for main task: 0.1663\n",
      "\n",
      "Epoch 49 average dice loss for aux task: 0.0095\n",
      "\n",
      "Epoch 49 average total loss for both tasks: 0.2599\n",
      "--------------------\n",
      "Epoch 50 / 100\n",
      "\n",
      "Epoch 50 average dice loss for main task: 0.1641\n",
      "\n",
      "Epoch 50 average dice loss for aux task: 0.0094\n",
      "\n",
      "Epoch 50 average total loss for both tasks: 0.2565\n",
      "\n",
      "Current epoch: 50 current mean dice for main task: 0.8230\n",
      "Best mean dice for main task: 0.8315 at epoch: 10\n",
      "Current epoch: 50 current mean ssim for aux task: 0.9513\n",
      "--------------------\n",
      "Epoch 51 / 100\n",
      "\n",
      "Epoch 51 average dice loss for main task: 0.1618\n",
      "\n",
      "Epoch 51 average dice loss for aux task: 0.0081\n",
      "\n",
      "Epoch 51 average total loss for both tasks: 0.2516\n",
      "--------------------\n",
      "Epoch 52 / 100\n",
      "\n",
      "Epoch 52 average dice loss for main task: 0.1624\n",
      "\n",
      "Epoch 52 average dice loss for aux task: 0.0085\n",
      "\n",
      "Epoch 52 average total loss for both tasks: 0.2529\n",
      "--------------------\n",
      "Epoch 53 / 100\n",
      "\n",
      "Epoch 53 average dice loss for main task: 0.1674\n",
      "\n",
      "Epoch 53 average dice loss for aux task: 0.0093\n",
      "\n",
      "Epoch 53 average total loss for both tasks: 0.2613\n",
      "--------------------\n",
      "Epoch 54 / 100\n",
      "\n",
      "Epoch 54 average dice loss for main task: 0.1642\n",
      "\n",
      "Epoch 54 average dice loss for aux task: 0.0106\n",
      "\n",
      "Epoch 54 average total loss for both tasks: 0.2580\n",
      "--------------------\n",
      "Epoch 55 / 100\n",
      "\n",
      "Epoch 55 average dice loss for main task: 0.1604\n",
      "\n",
      "Epoch 55 average dice loss for aux task: 0.0090\n",
      "\n",
      "Epoch 55 average total loss for both tasks: 0.2504\n",
      "--------------------\n",
      "Epoch 56 / 100\n",
      "\n",
      "Epoch 56 average dice loss for main task: 0.1649\n",
      "\n",
      "Epoch 56 average dice loss for aux task: 0.0113\n",
      "\n",
      "Epoch 56 average total loss for both tasks: 0.2598\n",
      "--------------------\n",
      "Epoch 57 / 100\n",
      "\n",
      "Epoch 57 average dice loss for main task: 0.1636\n",
      "\n",
      "Epoch 57 average dice loss for aux task: 0.0095\n",
      "\n",
      "Epoch 57 average total loss for both tasks: 0.2558\n",
      "--------------------\n",
      "Epoch 58 / 100\n",
      "\n",
      "Epoch 58 average dice loss for main task: 0.1593\n",
      "\n",
      "Epoch 58 average dice loss for aux task: 0.0113\n",
      "\n",
      "Epoch 58 average total loss for both tasks: 0.2514\n",
      "--------------------\n",
      "Epoch 59 / 100\n",
      "\n",
      "Epoch 59 average dice loss for main task: 0.1570\n",
      "\n",
      "Epoch 59 average dice loss for aux task: 0.0094\n",
      "\n",
      "Epoch 59 average total loss for both tasks: 0.2459\n",
      "--------------------\n",
      "Epoch 60 / 100\n",
      "\n",
      "Epoch 60 average dice loss for main task: 0.1586\n",
      "\n",
      "Epoch 60 average dice loss for aux task: 0.0093\n",
      "\n",
      "Epoch 60 average total loss for both tasks: 0.2480\n",
      "\n",
      "Current epoch: 60 current mean dice for main task: 0.8207\n",
      "Best mean dice for main task: 0.8315 at epoch: 10\n",
      "Current epoch: 60 current mean ssim for aux task: 0.9619\n",
      "--------------------\n",
      "Epoch 61 / 100\n",
      "\n",
      "Epoch 61 average dice loss for main task: 0.1587\n",
      "\n",
      "Epoch 61 average dice loss for aux task: 0.0125\n",
      "\n",
      "Epoch 61 average total loss for both tasks: 0.2518\n",
      "--------------------\n",
      "Epoch 62 / 100\n",
      "\n",
      "Epoch 62 average dice loss for main task: 0.1592\n",
      "\n",
      "Epoch 62 average dice loss for aux task: 0.0104\n",
      "\n",
      "Epoch 62 average total loss for both tasks: 0.2502\n",
      "--------------------\n",
      "Epoch 63 / 100\n",
      "\n",
      "Epoch 63 average dice loss for main task: 0.1560\n",
      "\n",
      "Epoch 63 average dice loss for aux task: 0.0107\n",
      "\n",
      "Epoch 63 average total loss for both tasks: 0.2458\n",
      "--------------------\n",
      "Epoch 64 / 100\n",
      "\n",
      "Epoch 64 average dice loss for main task: 0.1579\n",
      "\n",
      "Epoch 64 average dice loss for aux task: 0.0100\n",
      "\n",
      "Epoch 64 average total loss for both tasks: 0.2479\n",
      "--------------------\n",
      "Epoch 65 / 100\n",
      "\n",
      "Epoch 65 average dice loss for main task: 0.1591\n",
      "\n",
      "Epoch 65 average dice loss for aux task: 0.0094\n",
      "\n",
      "Epoch 65 average total loss for both tasks: 0.2490\n",
      "--------------------\n",
      "Epoch 66 / 100\n",
      "\n",
      "Epoch 66 average dice loss for main task: 0.1600\n",
      "\n",
      "Epoch 66 average dice loss for aux task: 0.0108\n",
      "\n",
      "Epoch 66 average total loss for both tasks: 0.2519\n",
      "--------------------\n",
      "Epoch 67 / 100\n",
      "\n",
      "Epoch 67 average dice loss for main task: 0.1577\n",
      "\n",
      "Epoch 67 average dice loss for aux task: 0.0112\n",
      "\n",
      "Epoch 67 average total loss for both tasks: 0.2488\n",
      "--------------------\n",
      "Epoch 68 / 100\n",
      "\n",
      "Epoch 68 average dice loss for main task: 0.1575\n",
      "\n",
      "Epoch 68 average dice loss for aux task: 0.0083\n",
      "\n",
      "Epoch 68 average total loss for both tasks: 0.2454\n",
      "--------------------\n",
      "Epoch 69 / 100\n",
      "\n",
      "Epoch 69 average dice loss for main task: 0.1555\n",
      "\n",
      "Epoch 69 average dice loss for aux task: 0.0087\n",
      "\n",
      "Epoch 69 average total loss for both tasks: 0.2429\n",
      "--------------------\n",
      "Epoch 70 / 100\n",
      "\n",
      "Epoch 70 average dice loss for main task: 0.1551\n",
      "\n",
      "Epoch 70 average dice loss for aux task: 0.0106\n",
      "\n",
      "Epoch 70 average total loss for both tasks: 0.2443\n",
      "\n",
      "Current epoch: 70 current mean dice for main task: 0.8194\n",
      "Best mean dice for main task: 0.8315 at epoch: 10\n",
      "Current epoch: 70 current mean ssim for aux task: 0.9633\n",
      "--------------------\n",
      "Epoch 71 / 100\n",
      "\n",
      "Epoch 71 average dice loss for main task: 0.1559\n",
      "\n",
      "Epoch 71 average dice loss for aux task: 0.0092\n",
      "\n",
      "Epoch 71 average total loss for both tasks: 0.2441\n",
      "--------------------\n",
      "Epoch 72 / 100\n",
      "\n",
      "Epoch 72 average dice loss for main task: 0.1565\n",
      "\n",
      "Epoch 72 average dice loss for aux task: 0.0100\n",
      "\n",
      "Epoch 72 average total loss for both tasks: 0.2458\n",
      "--------------------\n",
      "Epoch 73 / 100\n",
      "\n",
      "Epoch 73 average dice loss for main task: 0.1564\n",
      "\n",
      "Epoch 73 average dice loss for aux task: 0.0108\n",
      "\n",
      "Epoch 73 average total loss for both tasks: 0.2464\n",
      "--------------------\n",
      "Epoch 74 / 100\n",
      "\n",
      "Epoch 74 average dice loss for main task: 0.1545\n",
      "\n",
      "Epoch 74 average dice loss for aux task: 0.0107\n",
      "\n",
      "Epoch 74 average total loss for both tasks: 0.2436\n",
      "--------------------\n",
      "Epoch 75 / 100\n",
      "\n",
      "Epoch 75 average dice loss for main task: 0.1552\n",
      "\n",
      "Epoch 75 average dice loss for aux task: 0.0101\n",
      "\n",
      "Epoch 75 average total loss for both tasks: 0.2439\n",
      "--------------------\n",
      "Epoch 76 / 100\n",
      "\n",
      "Epoch 76 average dice loss for main task: 0.1535\n",
      "\n",
      "Epoch 76 average dice loss for aux task: 0.0093\n",
      "\n",
      "Epoch 76 average total loss for both tasks: 0.2404\n",
      "--------------------\n",
      "Epoch 77 / 100\n",
      "\n",
      "Epoch 77 average dice loss for main task: 0.1525\n",
      "\n",
      "Epoch 77 average dice loss for aux task: 0.0089\n",
      "\n",
      "Epoch 77 average total loss for both tasks: 0.2386\n",
      "--------------------\n",
      "Epoch 78 / 100\n",
      "\n",
      "Epoch 78 average dice loss for main task: 0.1496\n",
      "\n",
      "Epoch 78 average dice loss for aux task: 0.0086\n",
      "\n",
      "Epoch 78 average total loss for both tasks: 0.2339\n",
      "--------------------\n",
      "Epoch 79 / 100\n",
      "\n",
      "Epoch 79 average dice loss for main task: 0.1567\n",
      "\n",
      "Epoch 79 average dice loss for aux task: 0.0099\n",
      "\n",
      "Epoch 79 average total loss for both tasks: 0.2459\n",
      "--------------------\n",
      "Epoch 80 / 100\n",
      "\n",
      "Epoch 80 average dice loss for main task: 0.1536\n",
      "\n",
      "Epoch 80 average dice loss for aux task: 0.0087\n",
      "\n",
      "Epoch 80 average total loss for both tasks: 0.2400\n",
      "\n",
      "Current epoch: 80 current mean dice for main task: 0.8217\n",
      "Best mean dice for main task: 0.8315 at epoch: 10\n",
      "Current epoch: 80 current mean ssim for aux task: 0.9657\n",
      "--------------------\n",
      "Epoch 81 / 100\n",
      "\n",
      "Epoch 81 average dice loss for main task: 0.1509\n",
      "\n",
      "Epoch 81 average dice loss for aux task: 0.0085\n",
      "\n",
      "Epoch 81 average total loss for both tasks: 0.2357\n",
      "--------------------\n",
      "Epoch 82 / 100\n",
      "\n",
      "Epoch 82 average dice loss for main task: 0.1515\n",
      "\n",
      "Epoch 82 average dice loss for aux task: 0.0085\n",
      "\n",
      "Epoch 82 average total loss for both tasks: 0.2365\n",
      "--------------------\n",
      "Epoch 83 / 100\n",
      "\n",
      "Epoch 83 average dice loss for main task: 0.1565\n",
      "\n",
      "Epoch 83 average dice loss for aux task: 0.0107\n",
      "\n",
      "Epoch 83 average total loss for both tasks: 0.2465\n",
      "--------------------\n",
      "Epoch 84 / 100\n",
      "\n",
      "Epoch 84 average dice loss for main task: 0.1528\n",
      "\n",
      "Epoch 84 average dice loss for aux task: 0.0083\n",
      "\n",
      "Epoch 84 average total loss for both tasks: 0.2384\n",
      "--------------------\n",
      "Epoch 85 / 100\n",
      "\n",
      "Epoch 85 average dice loss for main task: 0.1532\n",
      "\n",
      "Epoch 85 average dice loss for aux task: 0.0081\n",
      "\n",
      "Epoch 85 average total loss for both tasks: 0.2387\n",
      "--------------------\n",
      "Epoch 86 / 100\n",
      "\n",
      "Epoch 86 average dice loss for main task: 0.1518\n",
      "\n",
      "Epoch 86 average dice loss for aux task: 0.0093\n",
      "\n",
      "Epoch 86 average total loss for both tasks: 0.2380\n",
      "--------------------\n",
      "Epoch 87 / 100\n",
      "\n",
      "Epoch 87 average dice loss for main task: 0.1508\n",
      "\n",
      "Epoch 87 average dice loss for aux task: 0.0083\n",
      "\n",
      "Epoch 87 average total loss for both tasks: 0.2353\n",
      "--------------------\n",
      "Epoch 88 / 100\n",
      "\n",
      "Epoch 88 average dice loss for main task: 0.1503\n",
      "\n",
      "Epoch 88 average dice loss for aux task: 0.0087\n",
      "\n",
      "Epoch 88 average total loss for both tasks: 0.2349\n",
      "--------------------\n",
      "Epoch 89 / 100\n",
      "\n",
      "Epoch 89 average dice loss for main task: 0.1540\n",
      "\n",
      "Epoch 89 average dice loss for aux task: 0.0101\n",
      "\n",
      "Epoch 89 average total loss for both tasks: 0.2420\n",
      "--------------------\n",
      "Epoch 90 / 100\n",
      "\n",
      "Epoch 90 average dice loss for main task: 0.1520\n",
      "\n",
      "Epoch 90 average dice loss for aux task: 0.0092\n",
      "\n",
      "Epoch 90 average total loss for both tasks: 0.2381\n",
      "\n",
      "Current epoch: 90 current mean dice for main task: 0.8218\n",
      "Best mean dice for main task: 0.8315 at epoch: 10\n",
      "Current epoch: 90 current mean ssim for aux task: 0.9659\n",
      "--------------------\n",
      "Epoch 91 / 100\n",
      "\n",
      "Epoch 91 average dice loss for main task: 0.1513\n",
      "\n",
      "Epoch 91 average dice loss for aux task: 0.0096\n",
      "\n",
      "Epoch 91 average total loss for both tasks: 0.2376\n",
      "--------------------\n",
      "Epoch 92 / 100\n",
      "\n",
      "Epoch 92 average dice loss for main task: 0.1523\n",
      "\n",
      "Epoch 92 average dice loss for aux task: 0.0082\n",
      "\n",
      "Epoch 92 average total loss for both tasks: 0.2375\n",
      "--------------------\n",
      "Epoch 93 / 100\n",
      "\n",
      "Epoch 93 average dice loss for main task: 0.1504\n",
      "\n",
      "Epoch 93 average dice loss for aux task: 0.0087\n",
      "\n",
      "Epoch 93 average total loss for both tasks: 0.2352\n",
      "--------------------\n",
      "Epoch 94 / 100\n",
      "\n",
      "Epoch 94 average dice loss for main task: 0.1515\n",
      "\n",
      "Epoch 94 average dice loss for aux task: 0.0092\n",
      "\n",
      "Epoch 94 average total loss for both tasks: 0.2373\n",
      "--------------------\n",
      "Epoch 95 / 100\n",
      "\n",
      "Epoch 95 average dice loss for main task: 0.1495\n",
      "\n",
      "Epoch 95 average dice loss for aux task: 0.0086\n",
      "\n",
      "Epoch 95 average total loss for both tasks: 0.2337\n",
      "--------------------\n",
      "Epoch 96 / 100\n",
      "\n",
      "Epoch 96 average dice loss for main task: 0.1522\n",
      "\n",
      "Epoch 96 average dice loss for aux task: 0.0093\n",
      "\n",
      "Epoch 96 average total loss for both tasks: 0.2385\n",
      "--------------------\n",
      "Epoch 97 / 100\n",
      "\n",
      "Epoch 97 average dice loss for main task: 0.1485\n",
      "\n",
      "Epoch 97 average dice loss for aux task: 0.0079\n",
      "\n",
      "Epoch 97 average total loss for both tasks: 0.2314\n",
      "--------------------\n",
      "Epoch 98 / 100\n",
      "\n",
      "Epoch 98 average dice loss for main task: 0.1500\n",
      "\n",
      "Epoch 98 average dice loss for aux task: 0.0079\n",
      "\n",
      "Epoch 98 average total loss for both tasks: 0.2337\n",
      "--------------------\n",
      "Epoch 99 / 100\n",
      "\n",
      "Epoch 99 average dice loss for main task: 0.1508\n",
      "\n",
      "Epoch 99 average dice loss for aux task: 0.0106\n",
      "\n",
      "Epoch 99 average total loss for both tasks: 0.2378\n",
      "--------------------\n",
      "Epoch 100 / 100\n",
      "\n",
      "Epoch 100 average dice loss for main task: 0.1529\n",
      "\n",
      "Epoch 100 average dice loss for aux task: 0.0081\n",
      "\n",
      "Epoch 100 average total loss for both tasks: 0.2383\n",
      "\n",
      "Current epoch: 100 current mean dice for main task: 0.8223\n",
      "Best mean dice for main task: 0.8315 at epoch: 10\n",
      "Current epoch: 100 current mean ssim for aux task: 0.9645\n",
      "Done training! Best mean dice: 0.8315 at epoch: 10\n"
     ]
    }
   ],
   "source": [
    "# Import AsDiscrete transform to convert the output to discrete values\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from monai.transforms import AsDiscrete\n",
    "from pathlib import Path\n",
    "# Create model directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create model save path\n",
    "MODEL_NAME = \"main_2_aux_recon_pytorch_male_pelvic_segmentation_model_final.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "\n",
    "val_interval = 10\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "epoch_aux_loss_values = []\n",
    "epoch_total_loss_values = []\n",
    "main_metric_values = []\n",
    "aux_metric_values = []\n",
    "\n",
    "# Post transforms for the main prostate zones: 2 classes + background\n",
    "post_pred_transform_main = Compose([AsDiscrete(argmax = True, to_onehot = main_out_channels)])\n",
    "post_label_transform_main = Compose([AsDiscrete(to_onehot = main_out_channels)])\n",
    "\n",
    "# Post transforms for the auxilliary prostate zones: 3 classes + background\n",
    "post_pred_transform_aux = Compose([AsDiscrete(argmax = True, to_onehot = aux_out_channels)])\n",
    "post_label_transform_aux = Compose([AsDiscrete(to_onehot = aux_out_channels)])\n",
    "\n",
    "# Loss weights\n",
    "main_weight = 1.5\n",
    "aux_weight = 1.1\n",
    "\n",
    "#CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Epoch {epoch + 1} / {max_epochs}\")\n",
    "    # Put the model into training mode\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_aux_loss = 0\n",
    "    epoch_total_loss = 0\n",
    "    step = 0\n",
    "    for batch in train_dl:\n",
    "        step = step + 1\n",
    "        inputs = batch[\"image\"].permute(0, 1, 4, 2, 3).to(device)\n",
    "        labels = batch[\"mask\"].to(device) # Permute beccause of torch upsample\n",
    "\n",
    "        # Modify the main labels to match the output of the main decoder\n",
    "        main_labels = labels.clone()\n",
    "        main_labels[(main_labels != organs_dict['Transition zone']) & (main_labels != organs_dict['Central gland'])] = 0.0\n",
    "        main_labels[main_labels == organs_dict['Transition zone']] = 1.0\n",
    "        main_labels[main_labels == organs_dict['Central gland']] = 2.0\n",
    "\n",
    "        # Modify the auxilliary labels to match the output of the auxilliary decoder\n",
    "        # aux_labels = labels.clone()\n",
    "        # aux_labels[(aux_labels != organs_dict['Bladder']) & (aux_labels != organs_dict['Rectum']) & (aux_labels != organs_dict['Seminal vesicle'])] = 0.0\n",
    "        # aux_labels[aux_labels == organs_dict['Bladder']] = 1.0\n",
    "        # aux_labels[aux_labels == organs_dict['Rectum']] = 2.0\n",
    "        # aux_labels[aux_labels == organs_dict['Seminal vesicle']] = 3.0\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        main_seg, aux_recon = model(inputs) \n",
    "        main_seg, aux_recon = main_seg.permute(0, 1, 3, 4, 2), aux_recon.permute(0, 1, 3, 4, 2) # Permute back to BNHWD\n",
    "\n",
    "        # Compute the loss functions\n",
    "        main_seg_loss = loss_function(main_seg, main_labels)\n",
    "        aux_recon_loss = reconstruction_loss(aux_recon, inputs.permute(0, 1, 3, 4, 2))\n",
    "\n",
    "        # Compute the total loss\n",
    "        loss = main_weight * main_seg_loss + aux_weight * aux_recon_loss\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Find the gradients of the loss w.r.t the model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add the loss to the epoch loss\n",
    "        epoch_loss = epoch_loss + main_seg_loss.item()\n",
    "        epoch_aux_loss = epoch_aux_loss + aux_recon_loss.item()\n",
    "        epoch_total_loss = epoch_total_loss + loss.item()\n",
    "    # Compute the average loss of the epoch\n",
    "    epoch_loss = epoch_loss / step\n",
    "    epoch_aux_loss = epoch_aux_loss / step\n",
    "    epoch_total_loss = epoch_total_loss / step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    epoch_total_loss_values.append(epoch_total_loss)\n",
    "    epoch_aux_loss_values.append(epoch_aux_loss)\n",
    "\n",
    "\n",
    "    # Print the average loss of the epoch\n",
    "    print(f\"\\nEpoch {epoch + 1} average dice loss for main task: {epoch_loss:.4f}\")\n",
    "    print(f\"\\nEpoch {epoch + 1} average dice loss for aux task: {epoch_aux_loss:.4f}\")\n",
    "    print(f\"\\nEpoch {epoch + 1} average total loss for both tasks: {epoch_total_loss:.4f}\")\n",
    "\n",
    "    # Step the scheduler after every epoch\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print loss and evaluate model when epoch is divisible by val_interval\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        #print(f\"Epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "        # Put the model into evaluation mode\n",
    "        model.eval()\n",
    "        # Disable gradient calculation\n",
    "        with torch.inference_mode():\n",
    "            val_ssim = []\n",
    "            # Loop through the validation data\n",
    "            for val_data in val_dl:\n",
    "                val_inputs, val_labels = val_data[\"image\"].permute(0, 1, 4, 2, 3).to(device), val_data[\"mask\"].to(device)\n",
    "                # Modify the main labels to match the output of the main decoder\n",
    "                val_main_labels = val_labels.clone()\n",
    "                val_main_labels[(val_main_labels != organs_dict['Transition zone']) & (val_main_labels != organs_dict['Central gland'])] = 0.0\n",
    "                val_main_labels[val_main_labels == organs_dict['Transition zone']] = 1.0\n",
    "                val_main_labels[val_main_labels == organs_dict['Central gland']] = 2.0\n",
    "\n",
    "                # # Modify the auxilliary labels to match the output of the auxilliary decoder\n",
    "                # val_aux_labels = val_labels.clone()\n",
    "                # val_aux_labels[(val_aux_labels != organs_dict['Bladder']) & (val_aux_labels != organs_dict['Rectum']) & (val_aux_labels != organs_dict['Seminal vesicle'])] = 0.0\n",
    "                # val_aux_labels[val_aux_labels == organs_dict['Bladder']] = 1.0\n",
    "                # val_aux_labels[val_aux_labels == organs_dict['Rectum']] = 2.0\n",
    "                # val_aux_labels[val_aux_labels == organs_dict['Seminal vesicle']] = 3.0\n",
    "\n",
    "\n",
    "\n",
    "                # Forward pass\n",
    "                val_main_outputs, val_aux_outputs = model(val_inputs)\n",
    "                val_main_outputs, val_aux_outputs = val_main_outputs.permute(0, 1, 3, 4, 2), val_aux_outputs.permute(0, 1, 3, 4, 2)\n",
    "\n",
    "                # Transform main outputs and labels to calculate inference loss\n",
    "                val_main_outputs = [post_pred_transform_main(i) for i in decollate_batch(val_main_outputs)]\n",
    "                val_main_labels = [post_label_transform_main(i) for i in decollate_batch(val_main_labels)]\n",
    "                # Compute dice metric for current iteration\n",
    "                dice_metric_main(y_pred = val_main_outputs, y = val_main_labels)\n",
    "\n",
    "                # # Transform aux outputs and labels to calculate inference loss\n",
    "                val_aux_outputs = decollate_batch(val_aux_outputs)\n",
    "                val_inputs = decollate_batch(val_inputs.permute(0, 1, 3, 4, 2))\n",
    "\n",
    "                for r in range(len(val_aux_outputs)):\n",
    "                    inp = val_inputs[r].cpu().numpy()\n",
    "                    out = val_aux_outputs[r].cpu().numpy()\n",
    "                    val_ssim.append(ssim(inp, out, channel_axis=0, data_range=inp.max() - inp.min()))\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                #dice_metric_aux(y_pred = val_aux_outputs, y = val_aux_labels)\n",
    "\n",
    "            # Compute the average metric value across all iterations\n",
    "            main_metric = dice_metric_main.aggregate().item()\n",
    "            aux_metric = np.mean(val_ssim)\n",
    "            main_metric_values.append(main_metric)\n",
    "            aux_metric_values.append(aux_metric)\n",
    "            \n",
    "            # Reset the metric for next validation run\n",
    "            dice_metric_main.reset()\n",
    "            #dice_metric_aux.reset()\n",
    "\n",
    "\n",
    "            # If the metric is better than the best seen so far, save the model\n",
    "            if main_metric > best_metric:\n",
    "                best_metric = main_metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "                print(\"saved new best metric model\")\n",
    "            \n",
    "            print(\n",
    "                f\"\\nCurrent epoch: {epoch + 1} current mean dice for main task: {main_metric:.4f}\"\n",
    "                f\"\\nBest mean dice for main task: {best_metric:.4f} at epoch: {best_metric_epoch}\"\n",
    "                f\"\\nCurrent epoch: {epoch + 1} current mean ssim for aux task: {aux_metric:.4f}\"\n",
    "                )\n",
    "            \n",
    "\n",
    "# When training is complete:\n",
    "print(f\"Done training! Best mean dice: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "\n",
    "                \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Trained model on half resolution\n",
    "2. Decreased LR and trained a bit more\n",
    "3. Use higher resolution\n",
    "4. Decrease LR and train a bit more\n",
    "Model2: Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save epoch loss and metric values based on the model name\n",
    "import pickle\n",
    "pref = f\"{MODEL_NAME.split('.')[0]}\"\n",
    "with open(MODEL_PATH/f\"{pref}_epoch_loss_values.pkl\", \"wb\") as f:\n",
    "    pickle.dump(epoch_loss_values, f)\n",
    "with open(MODEL_PATH/f\"{pref}_epoch_aux_loss_values.pkl\", \"wb\") as f:\n",
    "    pickle.dump(epoch_aux_loss_values, f)\n",
    "with open(MODEL_PATH/f\"{pref}_epoch_total_loss_values.pkl\", \"wb\") as f:\n",
    "    pickle.dump(epoch_total_loss_values, f)\n",
    "with open(MODEL_PATH/f\"{pref}_main_metric_values.pkl\", \"wb\") as f:\n",
    "    pickle.dump(main_metric_values, f)\n",
    "with open(MODEL_PATH/f\"{pref}_aux_metric_values.pkl\", \"wb\") as f:\n",
    "    pickle.dump(aux_metric_values, f)\n",
    "\n",
    "# # Open the saved files\n",
    "# with open(MODEL_PATH/\"epoch_loss_values.pkl\", \"rb\") as f:\n",
    "#     epoch_loss_values = pickle.load(f)\n",
    "# with open(MODEL_PATH/\"metric_values.pkl\", \"rb\") as f:\n",
    "#     metric_values = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform inference on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from monai.metrics import DiceMetric\n",
    "# Import AsDiscrete transform to convert the output to discrete values\n",
    "#from skimage.metrics import structural_similarity as ssim\n",
    "from monai.transforms import AsDiscrete\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "main_out_channels = 3 # Number of structures 2 + background\n",
    "aux_out_channels = 1 # Number of structures 3 + background\n",
    "\n",
    "# Create model directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_NAME = \"main_2_aux_recon_pytorch_male_pelvic_segmentation_model.pth\"\n",
    "BATCH_SIZE_TEST = 2 # batcH size of 1 to evaluate one image at a time\n",
    "\n",
    "# Evaluation metrics\n",
    "dice_metric_main = DiceMetric(include_background=False, reduction=\"mean\")# Collect the loss and metric values for every iteration\n",
    "dice_metric_aux = DiceMetric(include_background=False, reduction=\"mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create transforms for test images during forwrad pass\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys = [\"image\", \"mask\"]),\n",
    "        EnsureChannelFirstd(keys = [\"image\", \"mask\"]),\n",
    "        ScaleIntensityd(keys = \"image\"),\n",
    "        CropForegroundd(keys = [\"image\", \"mask\"], source_key = \"image\"),\n",
    "        Spacingd(\n",
    "            keys = [\"image\", \"mask\"],\n",
    "            pixdim = [0.75, 0.75, 2.5],\n",
    "            mode = (\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        CenterSpatialCropd(keys = [\"image\", \"mask\"], roi_size = (256, 256, 40)),\n",
    "        SpatialPadd(keys = [\"image\", \"mask\"], spatial_size = (256, 256, 40))\n",
    "\n",
    "    ])\n",
    "\n",
    "# Create post transforms for results of forward pass\n",
    "post_pred_transform_main = Compose([AsDiscrete(argmax = True, to_onehot = main_out_channels)])\n",
    "post_label_transform_main = Compose([AsDiscrete(to_onehot = main_out_channels)])\n",
    "\n",
    "# # Post transforms for the auxilliary prostate zones: 3 classes + background\n",
    "# post_pred_transform_aux = Compose([AsDiscrete(argmax = True, to_onehot = aux_out_channels)])\n",
    "# post_label_transform_aux = Compose([AsDiscrete(to_onehot = aux_out_channels)])\n",
    "\n",
    "# Create test dataset to apply transforms to test images\n",
    "test_ds = Dataset(data = test_files, transform = test_transforms)\n",
    "\n",
    "# Create test dataloader to load images in batches\n",
    "test_dl = DataLoader(test_ds, batch_size = BATCH_SIZE_TEST, shuffle = False, num_workers = 4)\n",
    "\n",
    "# Load the best saved model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MTLResidualAttention3DUnet(in_channels = 1, main_out_channels = main_out_channels , aux_out_channels = aux_out_channels, n_channels = [32, 64, 128, 256, 512], gated_attention = True).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH/MODEL_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Eric\\multi_task_learning\\ml_cw2\\multi_task_learning\\.venv\\lib\\site-packages\\monai\\data\\__init__.py:120: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  t = cls([], dtype=storage.dtype, device=storage.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Dice: 0.8044\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# Inference loop\n",
    "with torch.inference_mode(): # Disaable gradient tracking\n",
    "    dice_metric_main.reset()\n",
    "    #dice_metric_aux.reset()\n",
    "\n",
    "    for test_data in test_dl:\n",
    "        test_inputs, test_labels = test_data[\"image\"].permute(0, 1, 4, 2, 3).to(device), test_data[\"mask\"].to(device)\n",
    "        # Modify the main labels to match output of main decoder\n",
    "        test_main_labels = test_labels.clone()\n",
    "        test_main_labels[(test_main_labels != organs_dict['Transition zone']) & (test_main_labels != organs_dict['Central gland'])] = 0.0\n",
    "        test_main_labels[test_main_labels == organs_dict['Transition zone']] = 1.0\n",
    "        test_main_labels[test_main_labels == organs_dict['Central gland']] = 2.0\n",
    "\n",
    "        # # Modify the aux labels to match output of aux decoder\n",
    "        # test_aux_labels = test_labels.clone()\n",
    "        # test_aux_labels[(test_aux_labels != organs_dict['Bladder']) & (test_aux_labels != organs_dict['Rectum']) & (test_aux_labels != organs_dict['Seminal vesicle'])] = 0.0\n",
    "        # test_aux_labels[test_aux_labels == organs_dict['Bladder']] = 1.0\n",
    "        # test_aux_labels[test_aux_labels == organs_dict['Rectum']] = 2.0\n",
    "        # test_aux_labels[test_aux_labels == organs_dict['Seminal vesicle']] = 3.0\n",
    "\n",
    "        # Forward pass\n",
    "        test_main_outputs, test_aux_outputs = model(test_inputs)\n",
    "        test_main_outputs, test_aux_outputs = test_main_outputs.permute(0, 1, 3, 4, 2), test_aux_outputs.permute(0, 1, 3, 4, 2)\n",
    "\n",
    "        # Post transform the outputs and labels before making inference\n",
    "        test_main_outputs = [post_pred_transform_main(i) for i in decollate_batch(test_main_outputs)]\n",
    "        test_main_labels = [post_label_transform_main(i) for i in decollate_batch(test_main_labels)]\n",
    "\n",
    "        # test_aux_outputs = [post_pred_transform_aux(i) for i in decollate_batch(test_aux_outputs)]\n",
    "        # test_main_labels = [post_label_transform_aux(i) for i in decollate_batch(test_aux_labels)]\n",
    "\n",
    "        # Compute dice metric for the curent iteration\n",
    "        dice_metric_main(y_pred = test_main_outputs, y = test_main_labels)\n",
    "        #dice_metric_aux(y_pred = test_aux_outputs, y = test_aux_labels)\n",
    "    \n",
    "\n",
    "    # Obtain the metric values for class 1 (Transition zone) and class 2 (Central gland), class 0 is background is ignored\n",
    "    test_dice_scores = {'Transition zone': dice_metric_main.get_buffer()[:, 0].cpu().numpy().tolist(),\n",
    "                        'Central gland': dice_metric_main.get_buffer()[:, 1].cpu().numpy().tolist()}\n",
    "\n",
    "    # Aggregate the final mean dice result\n",
    "    test_metric = dice_metric_main.aggregate().item()\n",
    "    #test_metric_aux = dice_metric_aux.aggregate().item()\n",
    "    #dice_metric_main.reset()\n",
    "    #dice_metric_aux.reset()\n",
    "\n",
    "print(f\"Test Mean Dice: {test_metric:.4f}\")\n",
    "\n",
    "# Save the test dice scores to a pickle file\n",
    "import pickle\n",
    "pref = f\"{MODEL_NAME.split('.')[0]}\"\n",
    "with open(MODEL_PATH/f\"{pref}_test_dice_scores.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_dice_scores, f)\n",
    "\n",
    "# To load the pickle file\n",
    "# with open(MODEL_PATH/f\"{pref}_test_dice_scores.pkl\", \"rb\") as f:\n",
    "#     test_dice_scores = pickle.load(f)\n",
    "\n",
    "\n",
    "# (np.mean(test_dice_scores[\"Central gland\"]) + np.mean(test_dice_scores[\"Transition zone\"]))/2 : mean of the dice scores of the two classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Dice: 0.8039\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Mean Dice: {test_metric:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b17ee10d58e5196f58a9e865da959de9ad0c1caf1221e35f5cfc186ae929fd74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
