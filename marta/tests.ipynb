{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from monai.utils    import set_determinism  \n",
    "from split_data     import split_data\n",
    "from transforms     import get_transforms\n",
    "from model              import ResidualAttention3DUnet, MTLResidualAttention3DUnet\n",
    "from train_model        import train_model\n",
    "from test_model         import test_model\n",
    "from train_model_base   import train_model_base\n",
    "from test_model_base    import test_model_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Splitting data into train-validate-test sets...\n",
      "The file does not exist\n",
      "The file does not exist\n",
      "Images have been divided into train-validate-test sets.\n",
      "Total number of images:  585\n",
      "Number of images train-validate-test:  16 - 2 - 2\n",
      "----------------------------------------\n",
      "Creating transformations...\n",
      "Transforms have been defined.\n"
     ]
    }
   ],
   "source": [
    "# If TRUE, evaluate test data\n",
    "TRAIN = 1\n",
    "TEST = 1\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    'BATCH_SIZE':       2,\n",
    "    'MAX_EPOCHS':       2,\n",
    "    'VAL_INTERVAL':     1,\n",
    "    'PRINT_INTERVAL':   1\n",
    "}\n",
    "\n",
    "# Set deterministic training for reproducibility\n",
    "set_determinism(seed = 2056)\n",
    "\n",
    "img_path = Path(\"../data\")\n",
    "train_files, val_files, test_files = split_data(img_path, scale=28)\n",
    "\n",
    "# Create transforms for training\n",
    "train_transforms, val_transforms, pred_main, label_main, pred_aux, label_aux = get_transforms()\n",
    "\n",
    "# Create an index dictionary for the organs\n",
    "all_organs =  [\"Background\", \"Bladder\", \"Bone\", \"Obturator internus\", \"Transition zone\", \"Central gland\", \"Rectum\", \"Seminal vesicle\", \"Neurovascular bundle\"]\n",
    "organs = {\n",
    "    'all': all_organs,\n",
    "    'main': [\"Transition zone\", \"Central gland\"],\n",
    "    'aux':  [\"Rectum\", \"Seminal vesicle\", \"Neurovascular bundle\"],\n",
    "    'dict': {organ: idx for idx, organ in enumerate(all_organs)}\n",
    "    }\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUXILIARY TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Starting model training...\n",
      "--------------------\n",
      "Epoch 1 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-25 16:09:22,340 - pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:1295: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  ret = func(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/monai/data/__init__.py:127: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if storage.is_cuda:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 average dice loss for main task: 1.0000\n",
      "\n",
      "Epoch 1 average dice loss for aux task: 1.0000\n",
      "\n",
      "Epoch 1 average total loss for both tasks: 2.6000\n",
      "----------------------------------------\n",
      "Testing on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:1295: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  ret = func(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/monai/data/__init__.py:127: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if storage.is_cuda:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new best metric model\n",
      "\n",
      "Current epoch: 1 current mean dice for main task: 0.0000\n",
      "Best mean dice for main task: 0.0000 at epoch: 1\n",
      "Current epoch: 1 current mean dice for aux task: 0.0000\n",
      "Done training! Best mean dice: 0.0000 at epoch: 1\n"
     ]
    }
   ],
   "source": [
    "model  = MTLResidualAttention3DUnet(in_channels = 1, main_out_channels = len(organs['main'])+1, aux_out_channels = len(organs['aux'])+1).to(device) \n",
    "train_model(model, device, params, train_files, train_transforms, val_files, val_transforms, organs, pred_main, label_main, pred_aux, label_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Starting model testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-25 16:17:36,979 - pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:1295: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  ret = func(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/monai/data/__init__.py:127: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if storage.is_cuda:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean dice for main task: 0.0000\n",
      "Mean dice for aux task: 0.0000\n"
     ]
    }
   ],
   "source": [
    "if TEST:\n",
    "    test_model(model, device, params, test_files, val_transforms, organs, pred_main, label_main, pred_aux, label_aux)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASE CASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Starting model training...\n",
      "--------------------\n",
      "Epoch 1 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-25 16:27:55,359 - pixdim[0] (qfac) should be 1 (default) or -1; setting qfac to 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:1295: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  ret = func(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/monai/data/__init__.py:127: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if storage.is_cuda:\n",
      "/opt/anaconda3/lib/python3.9/site-packages/monai/data/__init__.py:120: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  t = cls([], dtype=storage.dtype, device=storage.device)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model  \u001b[39m=\u001b[39m ResidualAttention3DUnet(in_channels \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, out_channels \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(organs[\u001b[39m'\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device) \n\u001b[1;32m      3\u001b[0m \u001b[39mif\u001b[39;00m TRAIN:\n\u001b[0;32m----> 4\u001b[0m     train_model_base(model, device, params, train_files, train_transforms, val_files, val_transforms, organs, pred_main, label_main)\n\u001b[1;32m      5\u001b[0m \u001b[39mif\u001b[39;00m TEST:\n\u001b[1;32m      6\u001b[0m     test_model_base(model, device, params, test_files, val_transforms, organs, pred_main, label_main)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/ML in Medical Imaging/Group work/ml_cw2/marta/train_model_base.py:98\u001b[0m, in \u001b[0;36mtrain_model_base\u001b[0;34m(model, device, params, train_files, train_transforms, val_files, val_transforms, organs, pred_main, label_main)\u001b[0m\n\u001b[1;32m     95\u001b[0m main_labels \u001b[39m=\u001b[39m modify_labels(labels, organs)\n\u001b[1;32m     97\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m main_seg \u001b[39m=\u001b[39m model(inputs) \n\u001b[1;32m     99\u001b[0m main_seg \u001b[39m=\u001b[39m main_seg\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m2\u001b[39m) \u001b[39m# Permute back to BNHWD\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m# Compute the loss\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/ML in Medical Imaging/Group work/ml_cw2/marta/model.py:211\u001b[0m, in \u001b[0;36mResidualAttention3DUnet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    209\u001b[0m     g_gate \u001b[39m=\u001b[39m g_x[\u001b[39m0\u001b[39m]\n\u001b[1;32m    210\u001b[0m     x_residual \u001b[39m=\u001b[39m g_x[\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 211\u001b[0m     attn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention_blocks[i](skip_connections[x_residual], skip_connections[g_gate])\n\u001b[1;32m    212\u001b[0m     attentions\u001b[39m.\u001b[39mappend(attn)\n\u001b[1;32m    214\u001b[0m \u001b[39m#attentions = attentions[::-1]\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \n\u001b[1;32m    216\u001b[0m \u001b[39m# Pass the output of the attention blocks through the expanding path\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-ImperialCollegeLondon/ML in Medical Imaging/Group work/ml_cw2/marta/model.py:147\u001b[0m, in \u001b[0;36mattention_block.forward\u001b[0;34m(self, skip_connection, gate_signal)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m# Multiply the skip connection with the attention map\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m# Perform element-wise multiplication\u001b[39;00m\n\u001b[1;32m    145\u001b[0m skip_connection \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmul(skip_connection, attention_map)\n\u001b[0;32m--> 147\u001b[0m skip_connection \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv3d(in_channels \u001b[39m=\u001b[39m skip_connection\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], out_channels \u001b[39m=\u001b[39m skip_connection\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], kernel_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mto(device)(skip_connection)\n\u001b[1;32m    148\u001b[0m skip_connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_norm(skip_connection))\n\u001b[1;32m    150\u001b[0m \u001b[39mreturn\u001b[39;00m skip_connection\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "model  = ResidualAttention3DUnet(in_channels = 1, out_channels = len(organs['main'])+1).to(device) \n",
    "\n",
    "if TRAIN:\n",
    "    train_model_base(model, device, params, train_files, train_transforms, val_files, val_transforms, organs, pred_main, label_main)\n",
    "if TEST:\n",
    "    test_model_base(model, device, params, test_files, val_transforms, organs, pred_main, label_main)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
